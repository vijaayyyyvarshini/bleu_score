{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yW6wIhExqIhe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R-vNkTagqNPs"
      },
      "outputs": [],
      "source": [
        "# opening the train_source file in read mode\n",
        "my_file = open(\"train-source.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "train_source_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(train_source_list)):\n",
        "  train_source_list[item] = train_source_list[item].replace('</s>', '')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2-fEB8gr8kB"
      },
      "outputs": [],
      "source": [
        "train_source_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cMeA_KpUqgLk"
      },
      "outputs": [],
      "source": [
        "# opening the train-target file in read mode\n",
        "my_file = open(\"train-target.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "train_target_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(train_target_list)):\n",
        "  train_target_list[item] = train_target_list[item].replace('</s>', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# opening the test-target file in read mode\n",
        "my_file = open(\"test-source.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "test_source_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(test_source_list)):\n",
        "  test_source_list[item] = test_source_list[item].replace('</s>', '')\n",
        "\n",
        "# opening the test-target file in read mode\n",
        "my_file = open(\"test-target.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "test_target_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(test_target_list)):\n",
        "  test_target_list[item] = test_target_list[item].replace('</s>', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmUu_iTXqmx1",
        "outputId": "976a419a-0cff-4f41-e86c-a6e7fc1bf3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of training sets Source:  45172  Target : 45172\n",
            "length of test sets Source:  1001  Target : 1001\n"
          ]
        }
      ],
      "source": [
        "print(\"length of training sets Source: \", len(train_source_list), \" Target :\", len(train_target_list))\n",
        "print(\"length of test sets Source: \", len(test_source_list), \" Target :\", len(test_target_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wma9nXxgDpwZ"
      },
      "outputs": [],
      "source": [
        "#Anything goes ref: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
        "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WxSdOvaWEqD",
        "outputId": "38468216-4d3f-4451-a979-77bce2af9317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 1.000000\n",
            "Cumulative 2-gram: 1.000000\n",
            "Cumulative 3-gram: 1.000000\n",
            "Cumulative 4-gram: 1.000000\n"
          ]
        }
      ],
      "source": [
        "#For Train\n",
        "reference_train = train_source_list\n",
        "candidate_train = train_target_list[1]\n",
        "\n",
        "print('Cumulative 1-gram: %f' % sentence_bleu(reference_train, candidate_train, weights=(1, 0, 0, 0)))\n",
        "print('Cumulative 2-gram: %f' % sentence_bleu(reference_train, candidate_train, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % sentence_bleu(reference_train, candidate_train, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % sentence_bleu(reference_train, candidate_train, weights=(0.25, 0.25, 0.25, 0.25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6sGz7XVyd8cg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 1.000000\n",
            "Cumulative 2-gram: 1.000000\n",
            "Cumulative 3-gram: 0.989740\n",
            "Cumulative 4-gram: 0.963897\n"
          ]
        }
      ],
      "source": [
        "#For Test\n",
        "reference_test = test_source_list\n",
        "candidate_test = test_target_list[1]\n",
        "\n",
        "print('Cumulative 1-gram: %f' % sentence_bleu(reference_test, candidate_test, weights=(1, 0, 0, 0)))\n",
        "print('Cumulative 2-gram: %f' % sentence_bleu(reference_test, candidate_test, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % sentence_bleu(reference_test, candidate_test, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % sentence_bleu(reference_test, candidate_test, weights=(0.25, 0.25, 0.25, 0.25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TpzMu-0jTNDC"
      },
      "outputs": [],
      "source": [
        "#From scratch: https://stackoverflow.com/questions/56968434/bleu-score-in-python-from-scratch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "49CvGtpJXTs8"
      },
      "outputs": [],
      "source": [
        "def n_gram_generator(sentence,n= 2,n_gram= False):\n",
        "    '''\n",
        "    N-Gram generator with parameters sentence\n",
        "    n is for number of n_grams\n",
        "    The n_gram parameter removes repeating n_grams\n",
        "    '''\n",
        "    sentence = sentence.lower()  # converting to lower case\n",
        "    sent_arr = np.array(sentence.split())  # split to string arrays\n",
        "    length = len(sent_arr)\n",
        "\n",
        "    word_list = []\n",
        "    for i in range(length+1):\n",
        "        if i < n:\n",
        "            continue\n",
        "        word_range = list(range(i-n,i))\n",
        "        s_list = sent_arr[word_range]\n",
        "        string = ' '.join(s_list)  # converting list to strings\n",
        "        word_list.append(string) # append to word_list\n",
        "        if n_gram:\n",
        "            word_list = list(set(word_list))\n",
        "    return word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "14VgL85DXZul"
      },
      "outputs": [],
      "source": [
        "def bleu_score(original, reference):\n",
        "    '''\n",
        "    Bleu score function given a orginal and a machine translated sentences\n",
        "    '''\n",
        "    rf_length = len(reference.split())\n",
        "    o_length  = len(original.split())\n",
        "\n",
        "    # Brevity Penalty\n",
        "    if rf_length > o_length:\n",
        "        BP=1\n",
        "    else:\n",
        "        penality=1-(rf_length/o_length)\n",
        "        BP = np.exp(penality)\n",
        "\n",
        "    # Clipped precision\n",
        "    clipped_precision_score = []\n",
        "    for ngram_level in range(1, 4):  # 1-gram to 4-gram\n",
        "        \n",
        "        \n",
        "        original_ngram_list = n_gram_generator(original, ngram_level)\n",
        "        original_n_gram = Counter(original_ngram_list)\n",
        "        \n",
        "        reference_ngram_list = n_gram_generator(reference, ngram_level)\n",
        "        reference_n_gram = Counter(reference_ngram_list)\n",
        "        \n",
        "        \n",
        "        num_ngrams_in_translation = sum(reference_n_gram.values())  # number of ngrams in translation\n",
        "        \n",
        "        # iterate the unique ngrams in translation (candidate)\n",
        "        for j in reference_n_gram:\n",
        "            \n",
        "            if j in original_n_gram:  # if found in reference\n",
        "                \n",
        "                if reference_n_gram[j] > original_n_gram[j]:  # CLIPPING - if found in translation more than in source, clip\n",
        "                    reference_n_gram[j] = original_n_gram[j]\n",
        "                    \n",
        "            else:\n",
        "                reference_n_gram[j] = 0\n",
        "\n",
        "        #print (sum(machine_n_gram.values()), c)\n",
        "        clipped_precision_score.append(float(sum(reference_n_gram.values())) / num_ngrams_in_translation)\n",
        "\n",
        "    #print (clipped_precision_score)\n",
        "\n",
        "    weights = [0.25]*4\n",
        "\n",
        "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
        "    s = BP * math.exp(math.fsum(s))\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKNPslQhTP6G",
        "outputId": "4c674081-c120-4cac-cf4f-d907e0c4d886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score from scratch for Train files :  0.36787632499277756\n"
          ]
        }
      ],
      "source": [
        "#For Train Files\n",
        "original_train = train_source_list[1]\n",
        "reference_train = train_target_list[1]\n",
        "\n",
        "print (\"BLEU Score from scratch for Train files : \", bleu_score(original_train, reference_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score from scratch for Test files :  0.47287080450158786\n"
          ]
        }
      ],
      "source": [
        "#For Train Files\n",
        "original_test = test_source_list[1]\n",
        "reference_test = test_target_list[1]\n",
        "\n",
        "print (\"BLEU Score from scratch for Test files : \", bleu_score(original_test, reference_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e5c4b6e65ccaabe18f9cd3218992e678d372855fbc859c2eb66bba448f3faf11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
