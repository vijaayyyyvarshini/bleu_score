{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From scratch: https://stackoverflow.com/questions/56968434/bleu-score-in-python-from-scratch\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def n_gram_generator(sentence,n= 2,n_gram= False):\n",
    "    sentence = sentence.lower()  # converting to lower case\n",
    "    sent_arr = np.array(sentence.split())  # split to string arrays\n",
    "    length = len(sent_arr)\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(length+1):\n",
    "        if i < n:\n",
    "            continue\n",
    "        word_range = list(range(i-n,i))\n",
    "        s_list = sent_arr[word_range]\n",
    "        string = ' '.join(s_list)  # converting list to strings\n",
    "        word_list.append(string) # append to word_list\n",
    "        if n_gram:\n",
    "            word_list = list(set(word_list))\n",
    "    return word_list\n",
    "\n",
    "def from_scratch_bleu_score(original, reference):\n",
    "    '''\n",
    "    Bleu score function given a orginal and a reference ot target sentences\n",
    "    '''\n",
    "    rf_length = len(reference.split())\n",
    "    o_length  = len(original.split())\n",
    "\n",
    "    # Brevity Penalty\n",
    "    if rf_length > o_length:\n",
    "        BP=1\n",
    "    else:\n",
    "        penality=1-(rf_length/o_length)\n",
    "        BP = np.exp(penality)\n",
    "\n",
    "    # Clipped precision\n",
    "    clipped_precision_score = []\n",
    "    for ngram_level in range(1, 4):  # 1-gram to 4-gram\n",
    "        \n",
    "        \n",
    "        original_ngram_list = n_gram_generator(original, ngram_level)\n",
    "        original_n_gram = Counter(original_ngram_list)\n",
    "        \n",
    "        reference_ngram_list = n_gram_generator(reference, ngram_level)\n",
    "        reference_n_gram = Counter(reference_ngram_list)\n",
    "        \n",
    "        \n",
    "        num_ngrams_in_translation = sum(reference_n_gram.values())  # number of ngrams in translation\n",
    "        \n",
    "        # iterate the unique ngrams in translation (candidate)\n",
    "        for j in reference_n_gram:\n",
    "            \n",
    "            if j in original_n_gram:  # if found in reference\n",
    "                \n",
    "                if reference_n_gram[j] > original_n_gram[j]:  # CLIPPING - if found in translation more than in source, clip\n",
    "                    reference_n_gram[j] = original_n_gram[j]\n",
    "                    \n",
    "            else:\n",
    "                reference_n_gram[j] = 0\n",
    "\n",
    "        #print (sum(machine_n_gram.values()), c)\n",
    "        clipped_precision_score.append(float(sum(reference_n_gram.values())) / num_ngrams_in_translation)\n",
    "\n",
    "    #print (clipped_precision_score)\n",
    "\n",
    "    weights = [0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = BP * math.exp(math.fsum(s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Anything goes\n",
    "#Anything goes ref: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Source, Target):\n",
    "\n",
    "    # opening the train_source file in read mode\n",
    "    my_file = open(Source, \"r\", encoding='UTF-8')\n",
    "    data = my_file.read()\n",
    "    train_source_list = data.replace('\\n',\" \").split('<s>')\n",
    "    my_file.close()\n",
    "    for item in range(len(train_source_list)):\n",
    "        train_source_list[item] = train_source_list[item].replace('</s>', '')\n",
    "\n",
    "    # opening the train_target file in read mode\n",
    "    my_file = open(Target, \"r\", encoding='UTF-8')\n",
    "    data = my_file.read()\n",
    "    train_target_list = data.replace('\\n',\" \").split('<s>')\n",
    "    my_file.close()\n",
    "    for item in range(len(train_target_list)):\n",
    "        train_target_list[item] = train_target_list[item].replace('</s>', '')\n",
    "\n",
    "    # From Scratch\n",
    "    candidate = random.randint(0,len(train_target_list))\n",
    "    original_train = train_source_list[candidate]\n",
    "    reference_train = train_target_list[candidate]\n",
    "\n",
    "    From_Scratch_Score = from_scratch_bleu_score(original_train, reference_train)\n",
    "    print (\"BLEU Score from scratch : \", From_Scratch_Score)\n",
    "    \n",
    "    #Anything goes\n",
    "    \n",
    "    #Selecting a random sentence from target list\n",
    "    candidate = random.choice(train_target_list)\n",
    "    print('NLTK Sentence BLUE 1-gram: %f' % sentence_bleu(train_source_list, candidate, weights=(1, 0, 0, 0)))\n",
    "    print('NLTK Sentence BLUE 2-gram: %f' % sentence_bleu(train_source_list, candidate, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('NLTK Sentence BLUE 3-gram: %f' % sentence_bleu(train_source_list, candidate, weights=(0.33, 0.33, 0.33, 0)))\n",
    "    print('NLTK Sentence BLUE 4-gram: %f' % sentence_bleu(train_source_list, candidate, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score from scratch :  0.4583034067124109\n",
      "NLTK Sentence BLUE 1-gram: 1.000000\n",
      "NLTK Sentence BLUE 2-gram: 1.000000\n",
      "NLTK Sentence BLUE 3-gram: 1.000000\n",
      "NLTK Sentence BLUE 4-gram: 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"train-source.txt\",\"train-target.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score from scratch :  0.7183093189481372\n",
      "NLTK Sentence BLUE 1-gram: 1.000000\n",
      "NLTK Sentence BLUE 2-gram: 1.000000\n",
      "NLTK Sentence BLUE 3-gram: 0.996400\n",
      "NLTK Sentence BLUE 4-gram: 0.983281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"test-source.txt\",\"test-target.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c4b6e65ccaabe18f9cd3218992e678d372855fbc859c2eb66bba448f3faf11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
