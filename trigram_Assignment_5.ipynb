{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW6wIhExqIhe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-vNkTagqNPs"
      },
      "outputs": [],
      "source": [
        "# opening the file in read mode\n",
        "my_file = open(\"train-source.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "train_source_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(train_source_list)):\n",
        "  train_source_list[item] = train_source_list[item].replace('</s>', '')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2-fEB8gr8kB"
      },
      "outputs": [],
      "source": [
        "train_source_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMeA_KpUqgLk"
      },
      "outputs": [],
      "source": [
        "# opening the file in read mode\n",
        "my_file = open(\"train-target.txt\", \"r\", encoding='UTF-8')\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "train_target_list = data.replace('\\n',\" \").split('<s>')\n",
        "\n",
        "my_file.close()\n",
        "\n",
        "#Remove End Sentence Tags\n",
        "for item in range(len(train_target_list)):\n",
        "  train_target_list[item] = train_target_list[item].replace('</s>', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmUu_iTXqmx1",
        "outputId": "976a419a-0cff-4f41-e86c-a6e7fc1bf3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of training sets Source:  45172  Target : 45172\n"
          ]
        }
      ],
      "source": [
        "print(\"length of training sets Source: \", len(train_source_list), \" Target :\", len(train_target_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GymgOSyqpp8"
      },
      "outputs": [],
      "source": [
        "def make_markov_model(data, n_gram):\n",
        "    markov_model = {}\n",
        "    for i in range(len(data)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += data[i+j] + \"\"\n",
        "            next_state += data[i+j]+ data[j+n_gram] + \"\"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "    \n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "        \n",
        "    return markov_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yze59LVvqs3g",
        "outputId": "c88ba75d-fc57-40a1-8c5f-5a041a94a4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of states in bigram model for Train Source =  45164\n",
            "number of states in bigram model for Train Target =  45160\n"
          ]
        }
      ],
      "source": [
        "train_source_bigram_model = make_markov_model(train_source_list,n_gram=3)\n",
        "print(\"number of states in bigram model for Train Source = \", len(train_source_bigram_model.keys()))\n",
        "\n",
        "train_target_bigram_model = make_markov_model(train_target_list,n_gram=3)\n",
        "print(\"number of states in bigram model for Train Target = \", len(train_target_bigram_model.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wma9nXxgDpwZ"
      },
      "outputs": [],
      "source": [
        "#Anything goes ref: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
        "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
        "reference = train_source_list\n",
        "candidate = train_target_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WxSdOvaWEqD",
        "outputId": "38468216-4d3f-4451-a979-77bce2af9317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 1.000000\n",
            "Cumulative 2-gram: 1.000000\n",
            "Cumulative 3-gram: 1.000000\n",
            "Cumulative 4-gram: 1.000000\n"
          ]
        }
      ],
      "source": [
        "print('Cumulative 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
        "print('Cumulative 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sGz7XVyd8cg"
      },
      "outputs": [],
      "source": [
        "reference = train_source_list\n",
        "candidate = train_target_list\n",
        "\n",
        "print('Cumulative 1-gram: %f' % corpus_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
        "print('Cumulative 2-gram: %f' % corpus_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % corpus_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % corpus_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpzMu-0jTNDC"
      },
      "outputs": [],
      "source": [
        "#From scratch: https://stackoverflow.com/questions/56968434/bleu-score-in-python-from-scratch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49CvGtpJXTs8"
      },
      "outputs": [],
      "source": [
        "def n_gram_generator(sentence,n= 3,n_gram= False):\n",
        "    '''\n",
        "    N-Gram generator with parameters sentence\n",
        "    n is for number of n_grams\n",
        "    The n_gram parameter removes repeating n_grams\n",
        "    '''\n",
        "    sentence = sentence.lower()  # converting to lower case\n",
        "    sent_arr = np.array(sentence.split())  # split to string arrays\n",
        "    length = len(sent_arr)\n",
        "\n",
        "    word_list = []\n",
        "    for i in range(length+1):\n",
        "        if i < n:\n",
        "            continue\n",
        "        word_range = list(range(i-n,i))\n",
        "        s_list = sent_arr[word_range]\n",
        "        string = ' '.join(s_list)  # converting list to strings\n",
        "        word_list.append(string) # append to word_list\n",
        "        if n_gram:\n",
        "            word_list = list(set(word_list))\n",
        "    return word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14VgL85DXZul"
      },
      "outputs": [],
      "source": [
        "def bleu_score(original, machine_translated):\n",
        "    '''\n",
        "    Bleu score function given a orginal and a machine translated sentences\n",
        "    '''\n",
        "    mt_length = len(machine_translated.split())\n",
        "    o_length  = len(original.split())\n",
        "\n",
        "    # Brevity Penalty\n",
        "    if mt_length > o_length:\n",
        "        BP=1\n",
        "    else:\n",
        "        penality=1-(mt_length/o_length)\n",
        "        BP = np.exp(penality)\n",
        "\n",
        "    # Clipped precision\n",
        "    clipped_precision_score = []\n",
        "    for ngram_level in range(1, 4):  # 1-gram to 4-gram\n",
        "        \n",
        "        \n",
        "        original_ngram_list = n_gram_generator(original, ngram_level)\n",
        "        original_n_gram = Counter(original_ngram_list)\n",
        "        \n",
        "        machine_ngram_list = n_gram_generator(machine_translated, ngram_level)\n",
        "        machine_n_gram = Counter(machine_ngram_list)\n",
        "        \n",
        "        \n",
        "        num_ngrams_in_translation = sum(machine_n_gram.values())  # number of ngrams in translation\n",
        "        \n",
        "        # iterate the unique ngrams in translation (candidate)\n",
        "        for j in machine_n_gram:\n",
        "            \n",
        "            if j in original_n_gram:  # if found in reference\n",
        "                \n",
        "                if machine_n_gram[j] > original_n_gram[j]:  # CLIPPING - if found in translation more than in source, clip\n",
        "                    machine_n_gram[j] = original_n_gram[j]\n",
        "                    \n",
        "            else:\n",
        "                machine_n_gram[j] = 0\n",
        "\n",
        "        #print (sum(machine_n_gram.values()), c)\n",
        "        clipped_precision_score.append(float(sum(machine_n_gram.values())) / num_ngrams_in_translation)\n",
        "\n",
        "    #print (clipped_precision_score)\n",
        "\n",
        "    weights = [0.25]*4\n",
        "\n",
        "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
        "    s = BP * math.exp(math.fsum(s))\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKNPslQhTP6G",
        "outputId": "4c674081-c120-4cac-cf4f-d907e0c4d886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.36787632499277756\n"
          ]
        }
      ],
      "source": [
        "original = train_source_list[1]\n",
        "machine_translated = train_target_list[1]\n",
        "\n",
        "print (bleu_score(original, machine_translated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtt1Vgotf38X"
      },
      "outputs": [],
      "source": [
        "def bleu_score_2(original, machine_translated):\n",
        "    '''\n",
        "    Bleu score function given a orginal and a machine translated sentences\n",
        "    '''\n",
        "    mt_length = len(machine_translated.split())\n",
        "    o_length  = len(original)\n",
        "\n",
        "    # Brevity Penalty\n",
        "    if mt_length > o_length:\n",
        "        BP=1\n",
        "    else:\n",
        "        penality=1-(mt_length/o_length)\n",
        "        BP = np.exp(penality)\n",
        "\n",
        "    # Clipped precision\n",
        "    clipped_precision_score = []\n",
        "    for ngram_level in range(1, 4):  # 1-gram to 4-gram\n",
        "        \n",
        "        \n",
        "        original_ngram_list = n_gram_generator(original, ngram_level)\n",
        "        original_n_gram = Counter(original_ngram_list)\n",
        "        \n",
        "        machine_ngram_list = n_gram_generator(machine_translated, ngram_level)\n",
        "        machine_n_gram = Counter(machine_ngram_list)\n",
        "        \n",
        "        \n",
        "        num_ngrams_in_translation = sum(machine_n_gram.values())  # number of ngrams in translation\n",
        "        \n",
        "        # iterate the unique ngrams in translation (candidate)\n",
        "        for j in machine_n_gram:\n",
        "            \n",
        "            if j in original_n_gram:  # if found in reference\n",
        "                \n",
        "                if machine_n_gram[j] > original_n_gram[j]:  # CLIPPING - if found in translation more than in source, clip\n",
        "                    machine_n_gram[j] = original_n_gram[j]\n",
        "                    \n",
        "            else:\n",
        "                machine_n_gram[j] = 0\n",
        "\n",
        "        #print (sum(machine_n_gram.values()), c)\n",
        "        clipped_precision_score.append(float(sum(machine_n_gram.values())) / num_ngrams_in_translation)\n",
        "\n",
        "    #print (clipped_precision_score)\n",
        "\n",
        "    weights = [0.25]*4\n",
        "\n",
        "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
        "    s = BP * math.exp(math.fsum(s))\n",
        "    return s"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
